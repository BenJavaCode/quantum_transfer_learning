{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quantum_transfer_learning_complete2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8822cf9337504303bd9535c87d1275a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e0917d78bf5344418aca30a1fbbb5004",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_65c68e6d94d545e4822169ec3456ac86",
              "IPY_MODEL_7b6ee7df60ba420c86a70521ae93b3e5"
            ]
          }
        },
        "e0917d78bf5344418aca30a1fbbb5004": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65c68e6d94d545e4822169ec3456ac86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8391080863a64638804dc1a6c7767caa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02fae7a7ec8b41099940ed96864044bd"
          }
        },
        "7b6ee7df60ba420c86a70521ae93b3e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0efec0a635c749c7bfa9893d3391628d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 81274702.60it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a57e86d261f406a8cd4e1933ff20e57"
          }
        },
        "8391080863a64638804dc1a6c7767caa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02fae7a7ec8b41099940ed96864044bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0efec0a635c749c7bfa9893d3391628d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a57e86d261f406a8cd4e1933ff20e57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9fbbbebde68f49bfa28ec4cb058a3cc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c4264d07125d4274b80664830b49c55f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2f013ecaab8549568cfdea7dea311c3b",
              "IPY_MODEL_57c2e72c5c314f549cb361ed7d107d0d"
            ]
          }
        },
        "c4264d07125d4274b80664830b49c55f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f013ecaab8549568cfdea7dea311c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d9b2399cf2fe46248bd262af0298f2a2",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_025679cf779246f4a691ca65a385fe9c"
          }
        },
        "57c2e72c5c314f549cb361ed7d107d0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_122a5ad75af44a328ff777ec7e96b845",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:05&lt;00:00, 8.55MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ebdc29077eb445db58bfa4a6b76441e"
          }
        },
        "d9b2399cf2fe46248bd262af0298f2a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "025679cf779246f4a691ca65a385fe9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "122a5ad75af44a328ff777ec7e96b845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ebdc29077eb445db58bfa4a6b76441e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne_0JxBXWjxf",
        "outputId": "9af7d8bd-afdd-47aa-e189-7e2a54f37406"
      },
      "source": [
        "!pip install pennylane"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pennylane\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/7b/ebe11ec7ec45882cee379ea2e6026a1452205575b6aca3bd61a8b256f373/PennyLane-0.12.0-py3-none-any.whl (401kB)\n",
            "\r\u001b[K     |▉                               | 10kB 17.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20kB 21.6MB/s eta 0:00:01\r\u001b[K     |██▌                             | 30kB 12.2MB/s eta 0:00:01\r\u001b[K     |███▎                            | 40kB 8.9MB/s eta 0:00:01\r\u001b[K     |████                            | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 61kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 71kB 5.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 81kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 92kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 102kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 112kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 122kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 133kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 143kB 6.0MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 153kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 163kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 174kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 184kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 194kB 6.0MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 204kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 215kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 225kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 235kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 245kB 6.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 256kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 266kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 276kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 286kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 296kB 6.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 307kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 317kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 327kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 337kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 348kB 6.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 358kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 368kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 378kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 389kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 399kB 6.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 409kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pennylane) (1.18.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from pennylane) (2.5)\n",
            "Collecting semantic-version==2.6\n",
            "  Downloading https://files.pythonhosted.org/packages/28/be/3a7241d731ba89063780279a5433f5971c1cf41735b64a9f874b7c3ff995/semantic_version-2.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.6/dist-packages (from pennylane) (1.3)\n",
            "Collecting appdirs\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pennylane) (1.4.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from pennylane) (0.10.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->pennylane) (4.4.2)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from autograd->pennylane) (0.16.0)\n",
            "Installing collected packages: semantic-version, appdirs, pennylane\n",
            "Successfully installed appdirs-1.4.4 pennylane-0.12.0 semantic-version-2.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WmnRcemWav-"
      },
      "source": [
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibJQA4rCWpkm"
      },
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']\n",
        "#These are the classes in the dataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "8822cf9337504303bd9535c87d1275a9",
            "e0917d78bf5344418aca30a1fbbb5004",
            "65c68e6d94d545e4822169ec3456ac86",
            "7b6ee7df60ba420c86a70521ae93b3e5",
            "8391080863a64638804dc1a6c7767caa",
            "02fae7a7ec8b41099940ed96864044bd",
            "0efec0a635c749c7bfa9893d3391628d",
            "3a57e86d261f406a8cd4e1933ff20e57"
          ]
        },
        "id": "junVoVCBWr9z",
        "outputId": "10386900-1272-492c-e19f-368e06582345"
      },
      "source": [
        "data_path = r\"/content/drive/My Drive/cifar10/data\"\n",
        "\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]) # mean and std from resnet18\n",
        "    ]))\n",
        "\n",
        "\n",
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "    ]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/drive/My Drive/cifar10/data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8822cf9337504303bd9535c87d1275a9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /content/drive/My Drive/cifar10/data/cifar-10-python.tar.gz to /content/drive/My Drive/cifar10/data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fomYY24hWspj"
      },
      "source": [
        "import random\n",
        "class_names = ['airplane', 'bird']\n",
        "label_map = {0: 0, 2: 1}\n",
        "\n",
        "cifar2_train = [(img, label_map[label])\n",
        "          for img, label in cifar10\n",
        "          if label in [0, 2]]\n",
        "\n",
        "cifar2_val = [(img, label_map[label])\n",
        "              for img, label in cifar10_val\n",
        "              if label in [0, 2]]\n",
        "              \n",
        "nt = len(cifar2_train) \n",
        "nv = len(cifar2_val)\n",
        "n_train = int(400)  #Edit: test and val data batches are the same size, for more consistent validation\n",
        "n_val = int(400)\n",
        "idxT = list(range(nt)) \n",
        "idxV = list(range(nv))  \n",
        "random.shuffle(idxT)  \n",
        "random.shuffle(idxV)\n",
        "\n",
        "train_idx = idxT[:n_train]\n",
        "val_idx = idxV[:n_val]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLb07q83WvCP",
        "outputId": "d0c12dff-4b08-4b79-98f3-0948e8366d49"
      },
      "source": [
        "from torch.utils import data\n",
        "image_datasets_raw = {'train': cifar2_train, 'val': cifar2_val}\n",
        "image_datasets = {x: data.Subset(image_datasets_raw[x], train_idx if x == 'train' else val_idx) for x in image_datasets_raw }\n",
        "\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=2) for x in ['train', 'val']}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "device = (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
        "print(f\"Training on device {device}.\")\n",
        "use_cuda = torch.cuda.is_available()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on device cpu.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T85YkLhW5dU"
      },
      "source": [
        "def train_model(model, loss_fn, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train() \n",
        "            else:\n",
        "                model.eval()  \n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "               #forward pass\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1) # inp, dim\n",
        "                    loss = loss_fn(outputs, labels)\n",
        "\n",
        "                    # backwards pass\n",
        "                    if phase == 'train':\n",
        "                        loss.backward() # calculate gradiens\n",
        "                        optimizer.step() # update params\n",
        "\n",
        "                #stats\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print('\\n')\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load weights of best model\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMuV25a2bBA7"
      },
      "source": [
        "#Some hyperparameters \n",
        "\n",
        "n_qubits = 4                \n",
        "step = 0.0004               \n",
        "batch_size = 4                        \n",
        "q_depth = 6                 \n",
        "q_delta = 0.01                              "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBuc1D09azjW"
      },
      "source": [
        "#if this throws exception, restart runtime, but do not reinstall pennylane package!!!\n",
        "\n",
        "dev = qml.device(\"default.qubit\", n_qubits) # name of device, number of qubits\n",
        "#Any computational object that can apply quantum operations, and return an measurement value is called a quantum device.\n",
        "# in this example i use the default.qubit device, which is a pure qubit state device"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0g_teflXHGl"
      },
      "source": [
        "# quantumn functions\n",
        "def H_layer(nqubits): # superposition func\n",
        "    for idx in range(nqubits): # loop for each qubit in system\n",
        "        qml.Hadamard(wires=idx) # apply the h-gate on this qubit\n",
        "\n",
        "\n",
        "def RY_layer(w):# parametirized qubit rotations around the y axis\n",
        "    for idx, element in enumerate(w):\n",
        "        qml.RY(element, wires=idx)\n",
        "\n",
        "#layer for entanglement\n",
        "def entangling_layer(nqubits):\n",
        "    for i in range(0, nqubits - 1, 2):  \n",
        "        qml.CNOT(wires=[i, i + 1])\n",
        "    for i in range(1, nqubits - 1, 2):  \n",
        "        qml.CNOT(wires=[i, i + 1])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyZcLjLhc73_",
        "outputId": "e10ab7d1-e783-4c4a-a6ee-5cddaaa5a497"
      },
      "source": [
        "#this is merely for showing how the entangeling is taking place. It has no apllication other than that.\n",
        "\n",
        "qbits= 4\n",
        "for i in range(0, qbits - 1, 2):  # Loop over even indices: i=0,2,...N-2\n",
        "        print(f'qubit {i} and tarbit {i+1}')\n",
        "for i in range(1, qbits - 1, 2):  # Loop over odd indices:  i=1,3,...N-3\n",
        "        print(f'cnbit {i} and tarbit {i+1}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "qubit 0 and tarbit 1\n",
            "qubit 2 and tarbit 3\n",
            "cnbit 1 and tarbit 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPomsPxLc9fB"
      },
      "source": [
        "q0-q1-q2-q3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVBIjtBNdbtg"
      },
      "source": [
        "#quantum node \n",
        "@qml.qnode(dev, interface=\"torch\")  # quantum device, pytorch interface\n",
        "def quantum_net(q_input_features, q_weights_flat): # out_tensor,  weight\n",
        "\n",
        "    # Reshape weights\n",
        "    q_weights = q_weights_flat.reshape(q_depth, n_qubits) # Returns a tensor with the same data and number of elements as input, but with the specified shape(6 rows 4 columns)\n",
        "\n",
        "    H_layer(n_qubits) #superposition\n",
        "\n",
        "    # Embed features in the quantum node\n",
        "    RY_layer(q_input_features) # rotation around y-axis based on q_input_features\n",
        "\n",
        "    # Sequence of trainable variational layers\n",
        "    for k in range(q_depth):\n",
        "        entangling_layer(n_qubits)\n",
        "        RY_layer(q_weights[k])\n",
        "\n",
        "    # Expectation values in the Z basis\n",
        "    exp_vals = [qml.expval(qml.PauliZ(position)) for position in range(n_qubits)] # measuring with the Z operator produces a classical output vector, suitable for additional post-processing.\n",
        "    return tuple(exp_vals) "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_l6Knc6XSAn"
      },
      "source": [
        "class QuantumNet(nn.Module): # subclass of the nn.Module which is the pytorch network module\n",
        "    \"\"\"\n",
        "    Torch module implementing the quantum network\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        This is the structure of the network \n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        self.pre_net = nn.Linear(512, n_qubits) # input 512, out 4\n",
        "        self.q_params = nn.Parameter(q_delta * torch.randn(q_depth * n_qubits)) # 0.01 * torch.rand(6*4) # add to module parameters\n",
        "        self.post_net = nn.Linear(n_qubits, 2) # last layer\n",
        "\n",
        "    def forward(self, input_features):\n",
        "        \"\"\"\n",
        "        This is how the tensors are moving thought the quantum network\n",
        "        \"\"\"\n",
        "\n",
        "        # obtain the input features for the quantum circuit\n",
        "        # by reducing the feature dimension from 512 to 4\n",
        "        pre_out = self.pre_net(input_features) # look in init\n",
        "        q_in = torch.tanh(pre_out) * np.pi / 2.0 #activation function. with constant scaling by np.pi/2.0\n",
        "\n",
        "        # Apply the quantum circuit to each element of the batch and append to q_out\n",
        "        q_out = torch.Tensor(0, n_qubits) # tensor of size [0,4]\n",
        "        q_out = q_out.to(device) # sends q_out to device (cpu or gpu)\n",
        "        for elem in q_in: # 4 elements\n",
        "            q_out_elem = quantum_net(elem, self.q_params).float().unsqueeze(0) # \n",
        "            q_out = torch.cat((q_out, q_out_elem)) # concatinates and therby fills the empty tensor q_out in\n",
        "\n",
        "        # return the two-dimensional prediction from the postprocessing layer\n",
        "        return self.post_net(q_out) #returns the output of the last layer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22zotevYXYxS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "9fbbbebde68f49bfa28ec4cb058a3cc5",
            "c4264d07125d4274b80664830b49c55f",
            "2f013ecaab8549568cfdea7dea311c3b",
            "57c2e72c5c314f549cb361ed7d107d0d",
            "d9b2399cf2fe46248bd262af0298f2a2",
            "025679cf779246f4a691ca65a385fe9c",
            "122a5ad75af44a328ff777ec7e96b845",
            "6ebdc29077eb445db58bfa4a6b76441e"
          ]
        },
        "outputId": "f2e26cf9-a0b2-48e4-d5e3-0e7c01cb2919"
      },
      "source": [
        "model_hybrid = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "for param in model_hybrid.parameters(): # sets paramters of model to not be updated by grad\n",
        "    param.requires_grad = False \n",
        "\n",
        "\n",
        "# sets last layer of the model to be the quantum layer\n",
        "model_hybrid.fc = QuantumNet()\n",
        "\n",
        "# send the model to cuda or cpu according to the \"device\" object.\n",
        "#pennylane currently does not support cuda, so we have to use a cpu, as of now.\n",
        "model_hybrid = model_hybrid.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss() # loss function that combines negative likelihood loss and softmax\n",
        "\n",
        "optimizer_hybrid = optim.Adam(model_hybrid.fc.parameters(), lr=step) #step = 0.0004  \n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR( # each 7 steps decay lr by a factor of 0.1\n",
        "    optimizer_hybrid, step_size=7, gamma= 0.1\n",
        ")\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fbbbebde68f49bfa28ec4cb058a3cc5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxpjuER7hi-D"
      },
      "source": [
        "model_hybrid = train_model(\n",
        "    model = model_hybrid, loss_fn = loss_fn, optimizer = optimizer_hybrid, scheduler = exp_lr_scheduler, num_epochs=30\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i8sSIFpYBdd"
      },
      "source": [
        "#accuracy after 30 epochs 95% on vapl data."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtSWPeHfA3h"
      },
      "source": [
        "\"\"\"The reason - if you wonder- that the val loss is significantly less than the train loss,\n",
        " is because of the data augmentation that are used during training, but are not used during validation.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
